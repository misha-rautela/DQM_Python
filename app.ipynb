{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install Required Libraries\n",
    "Start by installing the necessary libraries for data manipulation, analysis, and quality checks. Some common libraries used for data quality management include:\n",
    "pandas for data manipulation.\n",
    "numpy for numerical operations.\n",
    "matplotlib for data visualization.\n",
    "openpyxl for working with Excel files (optional, if working with Excel data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load Data\n",
    "Use pandas to load your data into a DataFrame. This could be from various data sources such as CSV, Excel, databases, or APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data (CSV file as an example)\n",
    "data = pd.read_csv('sample_data.csv')\n",
    "\n",
    "# Show the first few rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Assess Current Data Quality\n",
    "Perform a quick assessment of the data quality by checking for missing values, duplicates, and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_data = data.isnull().sum()\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_data = data.duplicated().sum()\n",
    "\n",
    "# Basic descriptive statistics to identify outliers\n",
    "data_description = data.describe()\n",
    "\n",
    "print(\"Missing Data:\", missing_data)\n",
    "print(\"Duplicate Rows:\", duplicate_data)\n",
    "print(\"Data Description:\\n\", data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Data Cleansing\n",
    "Once the issues are identified, you can cleanse the data by handling missing values, removing duplicates, and correcting inconsistent data.\n",
    "\n",
    "Handling Missing Values\n",
    "You can either fill missing values with a specific value (mean, median, mode) or drop rows/columns with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mean (for numerical columns)\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Drop rows with missing values\n",
    "# data.dropna(inplace=True)\n",
    "\n",
    "# Alternatively, you can fill missing values with a placeholder for categorical data\n",
    "# data['column_name'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Duplicates\n",
    "Remove duplicate rows in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformation\n",
    "Standardize and normalize data if needed, such as converting strings to lowercase or removing special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all string data in a column to lowercase\n",
    "data['name'] = data['name'].str.lower()\n",
    "\n",
    "# Strip leading/trailing whitespaces from string columns\n",
    "data['email'] = data['email'].str.strip()\n",
    "\n",
    "data['address'] = data['address'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Data Validation\n",
    "Ensure that the data conforms to predefined rules, such as checking for valid ranges, formats, or values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Ensure 'age' column contains values within a valid range (18 to 100)\n",
    "data = data[(data['age'] >= 18) & (data['age'] <= 100)]\n",
    "\n",
    "# Example: Check that 'email' column contains valid email addresses\n",
    "import re\n",
    "\n",
    "def is_valid_email(email):\n",
    "    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "    return bool(re.match(pattern, email))\n",
    "\n",
    "data = data[data['email'].apply(is_valid_email)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Data Quality Monitoring (Automated Checks)\n",
    "Set up periodic checks to monitor the data quality. You can use scheduled tasks (like cron jobs) or set up a Python script to run data quality checks on a regular basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for periodic checks\n",
    "def data_quality_check(df):\n",
    "    # Example check: Ensure no missing values\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(\"Data Quality Issue: Missing values found.\")\n",
    "    else:\n",
    "        print(\"Data Quality Check Passed: No missing values.\")\n",
    "    \n",
    "    # Example check: Ensure no duplicates\n",
    "    if df.duplicated().sum() > 0:\n",
    "        print(\"Data Quality Issue: Duplicate rows found.\")\n",
    "    else:\n",
    "        print(\"Data Quality Check Passed: No duplicate rows.\")\n",
    "\n",
    "# Run the check\n",
    "data_quality_check(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Visualize Data Quality\n",
    "You can use visualizations to understand data quality metrics better, such as the distribution of missing values, duplicates, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizing missing data\n",
    "missing_data_percentage = data.isnull().mean() * 100\n",
    "missing_data_percentage.plot(kind='bar', color='skyblue')\n",
    "plt.title('Percentage of Missing Data per Column')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Missing Data (%)')\n",
    "plt.show()\n",
    "\n",
    "# Visualizing duplicates\n",
    "duplicate_percentage = (data.duplicated().mean() * 100)\n",
    "plt.bar(['Duplicates'], [duplicate_percentage], color='salmon')\n",
    "plt.title('Percentage of Duplicate Rows')\n",
    "plt.ylabel('Duplicate Data (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Create Data Quality Reports\n",
    "You can generate automated reports that summarize the quality checks, including issues found and steps taken to fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(data):\n",
    "    report = {\n",
    "        'Missing Data': data.isnull().sum(),\n",
    "        'Duplicate Rows': data.duplicated().sum(),\n",
    "        'Data Description': data.describe(),\n",
    "    }\n",
    "    return report\n",
    "\n",
    "# Generate a summary report\n",
    "report = generate_report(data)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Store Clean Data\n",
    "After cleansing and validation, save the cleaned dataset for further use or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new CSV file\n",
    "data.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Automate DQM with Python Scripts\n",
    "You can automate this whole process using Python scripts that run periodically (e.g., using cron jobs on Linux or Task Scheduler on Windows) to check and clean your data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
